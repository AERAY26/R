{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Performance Computing with  R\n",
    "\n",
    "## Eric Feigelson (Penn State)  edf@astro.psu.edu\n",
    "## 2nd East Asian Workshops in Astrostatistics    Summer 2018\n",
    "\n",
    "\n",
    "**Adapted from R scripts in Appendix B,  *Modern Statistical Methods for Astronomy With R Applications*,  Eric D. Feigelson & G. Jogesh Babu 2012  http://astrostatistics.psu.edu/MSMA**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R is written in C and some R functions (particularly vector operations) proceed at machine code speed.  But R is an interpreted language, and some functions (e.g. `for`, `if/else` and `while` loops) proceed at much slower speeds.\n",
    " \n",
    "R functions were changed to a `byte-code compiler` c2012, so on-the-fly compilation is reduced.  Python has the same compiler type. \n",
    "\n",
    "R code can often be improved for performance through improved structure & vectorization, by converting computationally-intensive portions to C or Fortran, by using parallel processing within R, and by using advanced CRAN packages for use on large CPU/GPU clusters or cloud computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed with some tests of operational speed for different coding practices.  Advice on speeding up R code can be found in the following references:\n",
    "  - The Art of R Programming, N. Matloff (2011, book, Chpt 11)\n",
    "  - At www.r-bloggers.com: FasteR! HigheR! StrongeR!, N. Ross (2013)\n",
    "  - At www.r-statistics.com: Speed up using JIT compiler, T. Galil (2012)\n",
    "  - Getting Started with doParallel and foreach, S. Weston & R. Calaway (2014)\n",
    "  - Simple Parallel Statistical Computing in R, L. Tierney (slides, 2003)\n",
    "  - State of the Art in Parallel Computing with R, M. Schmidberger et al. (J Stat Software, 2009)\n",
    "  - Tutorial: Parallel Computing with R on Lion and Hammer (RCC/PSU, 2013)\n",
    "  - HPC-R Exercises: Parallelism, D. Schmidt (2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I Benchmarking R codes\n",
    "\n",
    "We find that many R functions, such as the normal and beta distribution random number generators, are vector operations that operate at full speed of the CPU with O(N) scaling.  However, a `for` loop is can be 10-100 times slower, and nested `for` loops can be prohibitively time consuming.  Note that even simple operators like `:` and `<-` require function calls that can slow a program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N <- 1000000 # a million operations\n",
    "\n",
    "test1 <- function(n) {\n",
    "\tfoo1 <- rnorm(n) ; foo2 <- rbeta(n,5,5)\n",
    "\tfoo3 <- foo1 + foo2\n",
    "\treturn(foo3) }\n",
    "system.time(test1(N))# vector operations, fast, R ~ 10*system  \n",
    "system.time(test1(N*10))\n",
    "system.time(test1(N*100))\t# O(N) behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N\n",
    "test2 <- function(n) {\n",
    "\tfoo3 <- vector(length=n)\n",
    "\tfoo1 <- rnorm(n) ; foo2 <- rbeta(n,5,5)\n",
    "\tfor (i in 1:n) foo3[i] <- foo1[i] + foo2[i]\n",
    "\treturn(foo3) }\n",
    "system.time(test2(N))\n",
    "system.time(test2(N*10))# for loop, slightly slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 <- function(n) {\n",
    "\tfoo3 <- vector(length=n)\t\n",
    "\tfor (i in 1:n/10) \n",
    "\t\tfor (j in 1:10)  \n",
    "\t\tfoo1 <- rnorm(n) ; foo2 <- rbeta(n,5,5)\n",
    "\t\t\tfor (i in 1:n) {foo3[i] <- foo1[i] + foo2[i]}\n",
    "\treturn(foo3) }\n",
    "# system.time(test3(N))\t# Double loop, very slow\n",
    "system.time(test3(300))\n",
    "system.time(test3(3000))\t# O(N^2) behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II Profiling & debugging R programs\n",
    "\n",
    "Next, we turn to profiling procedures that help identify which steps are slowing the processing of a complicated code. `Rprof` is a utility in base-R while `microbenchmark` is one of several CRAN packages to help with improving the efficiency of R coding.  In the case of our `test2` function, we find that most of the time is spent generating random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rprof(\"profile.result\")\n",
    "invisible(test2(N))\n",
    "Rprof(NULL)\n",
    "summaryRprof(\"profile.result\")\n",
    "\n",
    "install.packages('microbenchmark', repos='https://cloud.r-project.org')\n",
    "library(microbenchmark)  ;  library(ggplot2)\n",
    "compare <- microbenchmark(test1(N/10), test2(N/10), times = 50)\n",
    "autoplot(compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R has built-in functions including `debug`, `browser`, `traceback`, `options(error=recover)`, and `tryCatch` to help the programmer understand complex codes.  CRAN packages include `debug`.  Run R within `gdb` to debug C code called by R scripts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III Speeding up R\n",
    "\n",
    "Clever use of the following can often speed up your program: sort, table, inner, outer, crossword, expand.grid, which, where, any, all, sum, cumsum, sumRows, cumprod, %% (modulo), etc.\n",
    "\n",
    "Following is a slow code with many calls to a random number generator, and a fast code with only one call.  This illustrates tradeoff between speed and memory usage. This and other examples of R speedup efforts are given by N. Matloff. A particular problem with R processing is that vectors are often unnecessarily copied and recalculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_ran2 <- 0\n",
    "system.time(\n",
    "    for (i in 1:N) { \n",
    "    ran.2 = rnorm(2) \n",
    "    sum_ran2 = sum_ran2 + max(ran.2) } \n",
    ")\n",
    "\n",
    "system.time (ran.many <- matrix(rnorm(2*N), ncol=2) ) \n",
    "system.time (sum(pmax(ran.many[,1], ran.many[,2])))\n",
    "# user-written loop is >10x slower than \n",
    "# R's built-in vector/matrix operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many operations can be sped up with R's `apply` functions: apply, sapply, lapply, etc.  lapply loops in compiled C code and can be fastest, although using numerics can be faster than using lists.   lapply procedures can be parallelized using `mclapply` in package `parallel`.  In the example below, the \"+\" function can be replaced by a more complex user-defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test4 <- function(n) {\n",
    "\tfoo1 <- rnorm(n) ; foo2 <- rbeta(n,5,5)\n",
    "\tfoo4 <- apply(cbind(foo1, foo2), 1, \"+\") \n",
    "\treturn(foo4)  }\n",
    "system.time(test4(N))\t\t# apply is not effective here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV Pre-compiling R code\n",
    "\n",
    "Since c2012, all R/CRAN functions are pre-compiled, but user-defined functions are not.  You can do this yourself and speed up your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.time(test2(N))\n",
    "library(compiler)\n",
    "comp_test2 <- cmpfun(test2)\n",
    "system.time(comp_test2(N)) \t# no improvement here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A related option is to use just-in-time (JIT) compiling in R that automatically compiles all functions their first time. Add the following at the beginning of the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(compiler)\n",
    "enableJIT(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion on speeding up R by N. Matloff: \"The moral of the story is that performance issues can be unpredictable.\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  V Parallel processing\n",
    "\n",
    "Important CRAN packages: multicore, snow,snowfall, doParallel,foreach, and plyr. Most parallelizations are related to `apply`, so if you can run your task in `apply`, you can parallelize.  \n",
    "\n",
    "Easy start to parallel processing: R package `doParallel` as an interface between the `parallel` package, a merger of CRAN's `multicore` and `snow` (Simple Network of Workstations packages, and the `foreach` package/function provided by the \n",
    "company MS Revolution Analytics.  This runs both on a single computer with multicores and on a cluster of processors.  With `doParallel`, 'an average R programmer can start \n",
    "executing parallel programs, without any previous experience in parallel computing'.\n",
    "\n",
    "Useful documentation:\n",
    " - vignette(\"gettingstartedParallel\")\n",
    " - 'Introduction to parallel computing in R' (Clint Leach, 2014)\n",
    " - CRAN Task View on High Performance Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup multicore cluster\n",
    "# install.packages('doParallel', repos='https://cloud.r-project.org') \n",
    "library(doParallel)\n",
    "getDoParWorkers()   # Find number of cores available\n",
    "clus <- makeCluster(4)  \n",
    "registerDoParallel(clus) \n",
    "ncores <- getDoParWorkers() ; ncores\n",
    "# stopCluster(clus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test5 <- function(n) {   # single-core module, inefficient loop\n",
    "     for(i in 1:n)  {\n",
    "         for (j in 1:n) { foo1 <- rnorm(n) + rbeta(n,5,5) }\n",
    "         }\n",
    "     }\n",
    "\n",
    "test6 <- function(n) {   # multi-core module, inefficient loop\n",
    "     foreach(i = 1:n) %dopar% {\n",
    "         for (j in 1:n) { foo1 <- rnorm(n) + rbeta(n,5,5) }\n",
    "         }\n",
    "     }\n",
    "\n",
    "system.time(test5(600))\n",
    "system.time(test6(600))  # O(ncores) speed improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII. Schematic Portable Batch System (pbs) script for supercomputer\n",
    "\n",
    "This is an `embarrassingly parallel` R pipeline\n",
    "\n",
    "Here each core performs identical analysis using different input data. Used for dissertation of Gabriel Caceres for planet search from 156,717 lightcurves from the Kepler 4-year mission (https://arxiv.org/abs/1905.09852).  Code is run on the Penn State ICS/aci-b CPU cluster.  \n",
    "\n",
    "Three elements:  (a) reserve 100 cores for 10 hours (wall-clock); (b) use GNU `parallel` utility for assigning jobs to free cores based on a list; (c) run `Rscript` utility for command-line batch mode run of an R script.\n",
    "\n",
    "#!/bin/bash\n",
    "#PBS -A edf-grant-number  # allocation\n",
    "#PBS -l nodes=1:ppn=5\t  # 5 nodes eachwith 10 processors\n",
    "#PBS -l walltime=10:00\t  # walltime\n",
    "#PBS -N SumSch_test       # job name\n",
    " \n",
    "#-#-# Software loaded into each core for each run\n",
    "\n",
    "module load R/3.2.0\n",
    "\n",
    "module load parallel/20150622\n",
    "\n",
    "cd /scratch/edf/SumSch.dir\n",
    "\n",
    "#-#-# Run pipeline.R for all stars in star.list \n",
    "\n",
    "parallel -a star.list \"Rscript pipeline.R dir.datafiles dir.controlfile\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:anaconda3]",
   "language": "R",
   "name": "conda-env-anaconda3-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
